---
layout: post
title:  "Maximum Likelihood With Bias-Corrected Calibration is Hard-To-Beat at Label Shift Adaptation"
date:   2020-07-08 12:21:00 -0700
categories: Publication
author: 'Avanti Shrikumar and Amr Alexandari'
---

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ZBXjE9QTruE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

Accepted to ICML 2020  
Authors: Amr Alexandari\*, Anshul Kundaje†, Avanti Shrikumar\*†  
(\*co-first authors, †co-corresponding authors)

## Introduction

Imagine we train a classifier to predict whether or not a person has a disease based on observed symptoms, and the classifier predicts reliably when deployed in the clinic. Suppose that there is a sudden surge in cases of the disease. During such an outbreak, the probability of persons having the disease given that they show symptoms rises, but the symptoms generated by the disease do not change. How can we adapt the classifier to cope with the difference in the baseline prevalence of the disease?

The problem of distribution shift in its most general form is intractable. However, there are reasonable assumptions that can help us solve this problem. If the disease generates similar symptoms in patients regardless of its spread in the community, then this is known as the label shift or prior probability shift (Amos, 2008), and it corresponds to anti-causal learning (i.e. predicting the cause $$y$$ from its effects $$\boldsymbol{x}$$). Anti-causal learning is appropriate for diagnosing diseases given observations of symptoms because diseases cause symptoms. In this example, a pandemic would induce a shift in $$p(y)$$; there would be a surge in cases. However, the process generating $$\boldsymbol{x}$$ given $$y$$ is fixed, i.e. $$p_s(\boldsymbol{x} \mid y) = p_t(\boldsymbol{x} \mid y)$$; the symptoms generated by the disease do not change. An automated diagnostic system should cope with the difference in the baseline prevalence of the disease and adjust its predictions accordingly. In [our paper](https://arxiv.org/abs/1901.06852), we propose using a maximum likelihood procedure with appropriate calibration for doing that, and we show that our approach is hard to beat at adapting to label shifts.

## Bias Corrected Temperature Scaling

Calibration has a long history in the machine learning literature (DeGroot and Fienberg, 1983; Platt, 1999; Zadrozny and Elkan; 2002; Niculescu-Mizil and Caruana, 2005; Kuleshov and Liang, 2015; Naeini et al., 2015; Kuleshov and Ermon, 2016). In the context of modern neural networks, Guo et al. (2017) showed that Temperature Scaling (TS), a single-parameter variant of Platt Scaling (Platt, 1999), was effective at reducing miscalibration.  Guo et al. (2017) compared TS to an approach defined as Vector Scaling (VS), where a different scaling parameter was used for each class along with class-specfic bias parameters and found that vector scaling had a tendency to perform slightly worse than TS as measured by a metric known as the Expected Calibration Error (Naeini et al., 2015).

![calibration comparison](https://github.com/kundajelab/kundajelab.github.io/blob/master/_posts/2020-07-08-figure.png?raw=true){: .center-image }

As shown in the figure, we often found that TS alone resulted in systematically biased estimates of $$p(y_i \mid \boldsymbol{x_k} )$$, while VS, a generalization of TS that contains both class-specific bias terms and class-specific scaling terms, did not exhibit as much systematic bias. Intrigued by this observation, we investigated the performance of two intermediaries between Temperature Scaling and Vector Scaling. The first, which we refer to as No Bias Vector Scaling (NBVS), is equivalent to vector scaling but with all the class-specific bias parameters fixed at zero. The second, which we refer to as Bias-Corrected Temperature Scaling (BCTS), is equivalent TS Scaling but with the addition of the class-specific bias terms from VS. As with TS and VS, the parameters are optimized to minimize the Negative Log Likelihood (NLL) on the validation set. Note that in the case of binary classification, the parameterization of BCTS reduces to Platt Scaling (Platt, 1999). Thus, BCTS can be viewed as a multi-class generalization of Platt scaling. Given fitted calibration parameters, performing calibration on test data takes O($$mN$$) time where $$m$$ is the number of output classes and $$N$$ is the number of datapoints. In our experiments, we found that BCTS is extremely effective when battling label shift.

## Another Look at Maximum Likelihood

Saerens et al. 2002 proposed an Expectation Maximization (EM) algorithm that estimates $$p_t(y)$$ but assumes access to a classifier that outputs the true source distribution conditional probabilities $$p_s(y \mid \boldsymbol{x})$$. This is a simple and scalable maximum likelihood approach, but unfortunately, estimates of $$p(y \mid \boldsymbol{x})$$ derived from modern neural networks are often poorly calibrated (Guo et al., 2017), and the lack of calibration can decrease the effectiveness of EM. For this reason, comparisons against the EM algorithm have been absent in the label shift adaptation literature.

Recently, Black Box Shift Estimation (BBSE) [Lipton et al., 2018] and a variant called Regularized Learning Label Shift (RLLS) [Azizzadenesheli et al., 2019]: leverage (possibly uncalibrated) predictions off-the-shelf classifiers to estimate the shift. Both of these moment-matching estimators require model retraining with importance weights which can be challenging at large scales. 

In our paper, we revisit maximum likelihood. We show that in combination with good calibration, a maximum likelihood procedure outperforms all other methods empirically and achieves state of the art results. Our approach is as follows:
<ul>
<li>Given a model that outputs predicted probabilities, calibrate the predictions of the model on a held-out validation using an appropriately strong calibration algorithm. We observed that BCTS and VS work well.</li>
<li>Average the calibrated predictions over this held-out validation set to obtain the estimated source-domain class priors. This is a principled strategy for estimating source-domain priors improves robustness to poor calibration.</li>
<li>Given samples from the target domain, use the estimated source-domain class priors and the calibrated predictor to optimize the concave maximum likelihood objective in w.r.t. the estimated target-domain class proportions.</li>
<li>After estimating target-domain class proportions, compute the adapted predictions for the target domain similar to the E-step of EM.</li>
</ul>
This work demonstrates that the maximum likelihood with appropriate calibration is a formidable and efficient baseline for label shift adaptation.

## Summary & Additional Resources

In summary:

<ul>
<li>The real world is dynamic and real world data distributions are capricious. Enabling automated systems to be robust to the ever-changing shifts present in real world data remains a critical goal of machine learning systems, and is known as "domain adaptation".</li>

<li>Label shift adaptation arises in settings such as medical diagnosis, and deals with shifts in the distribution of labels while the process generating the properties and manifestations of the label is fixed.</li>

<li>The popular calibration approach of Temperature Scaling (TS) does not tend to achieve the best results for adaptation to label shift, possibly owing to large systematic biases in the calibrated probabilities. Best results are obtained with variants of TS containing class-specific bias parameters that can correct for systematic bias.</li>

<li>Maximum likelihood algorithms, such as EM, achieve state-of-the-art results when used with an appropriate type of calibration. Although moment matching algorithms benefit from calibration, they did not tend to outperform maximum likelihood when the probabilities were well-calibrated.</li>
</ul>

A number of useful resources:

<ul>
<li>Paper: <a href="https://arxiv.org/abs/1901.06852">https://arxiv.org/abs/1901.06852</a></li>
<li>Notebooks reproducing experiments: <a href="https://github.com/kundajelab/labelshiftexperiments">https://github.com/kundajelab/labelshiftexperiments</a></li>
<li>Follow up work by Garg et al. that establishes sufficient conditions for consistency of the maximum likelihood approach and derives finite-sample error bounds: <a href="https://arxiv.org/abs/2003.07554">https://arxiv.org/abs/2003.07554</a></li>
</ul>
